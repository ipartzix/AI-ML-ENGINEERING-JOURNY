{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 01 — VECTORS (Linear Algebra for Machine Learning)\n",
    "\n",
    "This notebook is  **authoritative study note** for vectors. Use YouTube only to *support* this document, not replace it.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. What is a Vector?\n",
    "\n",
    "A **vector** is an ordered collection of numbers representing a point, direction, or feature list.\n",
    "\n",
    "In Machine Learning:\n",
    "\n",
    "* One data sample = **one vector**\n",
    "* Model weights = **vector**\n",
    "* Prediction = **dot product of vectors**\n",
    "\n",
    "Mathematically: (\\mathbf{x} = [x_1, x_2, ..., x_n]^T)\n",
    "\n",
    "Geometric view (2D):\n",
    "\n",
    "```\n",
    "^ y\n",
    "|        ● (x1, x2)\n",
    "|      ↗\n",
    "|    ↗  vector\n",
    "|  ↗\n",
    "+------------------> x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Scalars vs Vectors\n",
    "\n",
    "* **Scalar**: single number (temperature, learning rate)\n",
    "* **Vector**: ordered list (features, embeddings)\n",
    "\n",
    "Example:\n",
    "\n",
    "* Scalar: (\\alpha = 0.01)\n",
    "* Vector: (\\mathbf{x} = [2, -1, 4])\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Vector Dimensions\n",
    "\n",
    "The **dimension** of a vector is the number of components.\n",
    "\n",
    "* 2D → (\\mathbb{R}^2)\n",
    "* 3D → (\\mathbb{R}^3)\n",
    "* ML data → (\\mathbb{R}^n) (high-dimensional)\n",
    "\n",
    "Example:\n",
    "\n",
    "* Word-count vector for 10,000 words → (\\mathbb{R}^{10000})\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Zero Vector and Unit Vector\n",
    "\n",
    "### Zero Vector\n",
    "\n",
    "A vector with all components zero. (\\mathbf{0} = [0, 0, 0])\n",
    "\n",
    "* Has no direction\n",
    "* Acts as additive identity\n",
    "\n",
    "### Unit Vector\n",
    "\n",
    "A vector with magnitude = 1. (\\hat{v} = \\frac{\\mathbf{v}}{||\\mathbf{v}||})\n",
    "\n",
    "Graphical intuition:\n",
    "\n",
    "```\n",
    "Original vector:  ------>\n",
    "Unit vector:      -->\n",
    "(same direction, length = 1)\n",
    "```\n",
    "\n",
    "Used in:\n",
    "\n",
    "* Normalization\n",
    "* Cosine similarity\n",
    "* Gradient direction\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Norm (Magnitude) of a Vector\n",
    "\n",
    "The **norm** measures vector length.\n",
    "\n",
    "### L2 Norm (Euclidean norm)\n",
    "\n",
    "(||\\mathbf{x}||_2 = \\sqrt{x_1^2 + x_2^2 + ... + x_n^2})\n",
    "\n",
    "### L1 Norm\n",
    "\n",
    "(||\\mathbf{x}||_1 = |x_1| + |x_2| + ... + |x_n|)\n",
    "\n",
    "ML meaning:\n",
    "\n",
    "* L2 → smooth optimization\n",
    "* L1 → sparsity (feature selection)\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Distance Between Two Vectors\n",
    "\n",
    "Distance = norm of their difference. (d(\\mathbf{x}, \\mathbf{y}) = ||\\mathbf{x} - \\mathbf{y}||_2)\n",
    "\n",
    "Graphical idea:\n",
    "\n",
    "```\n",
    "● x\n",
    "|\\\n",
    "| \\\n",
    "|  \\  distance\n",
    "|   \\\n",
    "●----● y\n",
    "```\n",
    "\n",
    "Used in:\n",
    "\n",
    "* KNN\n",
    "* Clustering\n",
    "* Similarity search\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Sparsity in Vectors\n",
    "\n",
    "A **sparse vector** has many zeros.\n",
    "\n",
    "Example (bag-of-words): ([0, 0, 3, 0, 0, 1, 0, ...])\n",
    "\n",
    "Why it matters:\n",
    "\n",
    "* Saves memory\n",
    "* Faster computation\n",
    "* Common in NLP & recommender systems\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Vector Addition\n",
    "\n",
    "(\\mathbf{a} + \\mathbf{b} = [a_1+b_1, a_2+b_2, ...])\n",
    "\n",
    "Graphical intuition (head-to-tail):\n",
    "\n",
    "```\n",
    "----> a\n",
    "     ----> b\n",
    "--------------> a+b\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Scalar Multiplication\n",
    "\n",
    "(c\\mathbf{v} = [cv_1, cv_2, ...])\n",
    "\n",
    "Effect:\n",
    "\n",
    "* Scales magnitude\n",
    "* Keeps or flips direction\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Dot Product (Most Important)\n",
    "\n",
    "(\\mathbf{a} \\cdot \\mathbf{b} = a_1b_1 + a_2b_2 + ...)\n",
    "\n",
    "Geometric meaning: (\\mathbf{a} \\cdot \\mathbf{b} = ||a|| ||b|| \\cos(\\theta))\n",
    "\n",
    "Interpretations:\n",
    "\n",
    "* Measures similarity\n",
    "* Measures alignment\n",
    "* Core of prediction in ML\n",
    "\n",
    "In ML: (y = \\mathbf{w} \\cdot \\mathbf{x})\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Angle Between Vectors\n",
    "\n",
    "(\\cos(\\theta) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{||a|| ||b||})\n",
    "\n",
    "Used in:\n",
    "\n",
    "* Cosine similarity\n",
    "* Text embeddings\n",
    "* Attention mechanisms\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Projection of One Vector onto Another\n",
    "\n",
    "Projection of (a) onto (b): (\\text{proj}_b(a) = \\frac{a \\cdot b}{b \\cdot b} b)\n",
    "\n",
    "Graphical idea:\n",
    "\n",
    "```\n",
    "a\n",
    "|\\\n",
    "| \\  projection\n",
    "|  \\\n",
    "|   ----> b\n",
    "```\n",
    "\n",
    "Why it matters:\n",
    "\n",
    "* Least squares\n",
    "* Linear regression\n",
    "* Optimization\n",
    "\n",
    "---\n",
    "\n",
    "## 13. Orthogonality\n",
    "\n",
    "Two vectors are **orthogonal** if: (\\mathbf{a} \\cdot \\mathbf{b} = 0)\n",
    "\n",
    "Meaning:\n",
    "\n",
    "* No shared information\n",
    "* Independent directions\n",
    "\n",
    "In ML:\n",
    "\n",
    "* Decorrelated features\n",
    "* Stable optimization\n",
    "\n",
    "---\n",
    "\n",
    "## 14. Vectors as ML Data\n",
    "\n",
    "| Concept     | Vector Meaning    |\n",
    "| ----------- | ----------------- |\n",
    "| Data sample | Feature vector    |\n",
    "| Weights     | Parameter vector  |\n",
    "| Prediction  | Dot product       |\n",
    "| Loss        | Distance or error |\n",
    "\n",
    "---\n",
    "\n",
    "## 15. Mental Model (Important)\n",
    "\n",
    "Think of ML as:\n",
    "\n",
    "> Aligning weight vectors with data vectors to minimize error.\n",
    "\n",
    "Everything else builds on this.\n",
    "\n",
    "---\n",
    "\n",
    "## 16. What Comes Next\n",
    "\n",
    "After mastering this file:\n",
    "\n",
    "* Matrices = stacked vectors\n",
    "* Matrix-vector multiplication\n",
    "* Linear systems\n",
    "\n",
    "Do not move forward until this file feels **boringly obvious**.\n"
   ],
   "id": "53cce2c4a7bf92c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
